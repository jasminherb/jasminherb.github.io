---
layout: single
title:  "과적합 및 K겹 교차검증(5) "
---

# 과적합/교차검증


출처 : Thebook.io (모두의 딥러닝)

### 과적합

테스트셋을 만들지 않고 학습해 왔습니다. 그런데도 매번 정확도(accuracy)를 계산할 수 있었지요. 어째서 가능했을까요? 

지금까지 학습 데이터를 이용해 정확도를 측정한 것은 데이터에 들어 있는 모든 샘플을 그대로 테스트에 활용한 결과입니다. 

이를 통해 학습이 진행되는 상황을 파악할 수는 있지만, 새로운 데이터에 적용했을 때 어느 정도의 성능이 나올지는 알 수 없습니다. 

머신 러닝의 최종 목적은 과거의 데이터를 토대로 새로운 데이터를 예측하는 것입니다. 

즉, 새로운 데이터에 사용할 모델을 만드는 것이 최종 목적이므로 테스트셋을 만들어 정확한 평가를 병행하는 것이 매우 중요합니다.

학습셋만 가지고 평가할 때, 층을 더하거나 에포크(epoch) 값을 높여 실행 횟수를 늘리면 정확도가 계속해서 올라갈 수 있습니다. 

하지만 학습 데이터셋만으로 평가한 예측 성공률이 테스트셋에서도 그대로 나타나지는 않습니다. 

즉, 학습이 깊어져 학습셋 내부에서 성공률은 높아져도 테스트셋에서는 효과가 없다면 과적합이 일어나고 있는 것이지요.


과적합(overfitting)이란 모델이 학습 데이터셋 안에서는 일정 수준 이상의 예측 정확도를 보이지만, 새로운 데이터에 적용하면 잘 맞지 않는 것을 의미합니다.

과적합은 층이 너무 많거나 변수가 복잡해서 발생하기도 하고 테스트셋과 학습셋이 중복될 때 생기기도 합니다. 

특히 딥러닝은 학습 단계에서 입력층, 은닉층, 출력층의 노드들에 상당히 많은 변수가 투입됩니다. 

따라서 딥러닝을 진행하는 동안 과적합에 빠지지 않게 늘 주의해야 합니다.




### K겹 교차검증

앞서 데이터가 충분히 많아야 모델 성능도 향상된다고 했습니다. 

이는 학습과 테스트를 위한 데이터를 충분히 확보할수록 세상에 나왔을 때 더 잘 작동하기 때문입니다. 

하지만 실제 프로젝트에서는 데이터를 확보하는 것이 쉽지 않거나 많은 비용이 발생하는 경우도 있습니다. 

따라서 가지고 있는 데이터를 십분 활용하는 것이 중요합니다. 

특히 학습셋을 70%, 테스트셋을 30%로 설정할 경우 30%의 테스트셋은 학습에 이용할 수 없다는 단점이 있습니다. 

이를 해결하기 위해 고안된 방법이 k겹 교차 검증(k-fold cross validation)입니다. 

k겹 교차 검증이란 데이터셋을 여러 개로 나누어 하나씩 테스트셋으로 사용하고 나머지를 모두 합해서 학습셋으로 사용하는 방법입니다. 

이렇게 하면 가지고 있는 데이터의 100%를 학습셋으로 사용할 수 있고, 또 동시에 테스트셋으로도 사용할 수 있습니다. 

데이터셋을 다섯 개로 나눈 후 그중 네 개를 학습셋으로, 나머지 하나를 테스트셋으로 만들어 다섯 번의 학습을 순차적으로 실시하는 것이 5겹 교차 검증입니다. 

데이터를 원하는 수만큼 나누어 각각 학습셋과 테스트셋으로 사용되게 하는 함수는 사이킷런 라이브러리의 KFold() 함수입니다
