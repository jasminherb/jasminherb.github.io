---
layout: single
title:  " 물체 검출 with YOLO_V3 (31) "
---


# 물체검출

출처 : 컴퓨터 비전과 딥러닝




```python

import numpy as np
import cv2 as cv
import sys

def construct_yolo_v3():
    f=open('coco_names.txt', 'r')
    class_names=[line.strip() for line in f.readlines()]

    model=cv.dnn.readNet('yolov3.weights','yolov3.cfg')
    layer_names=model.getLayerNames()
    out_layers=[layer_names[i-1] for i in model.getUnconnectedOutLayers()]
    
    return model,out_layers,class_names
```

YOLOv3 모델을 생성하는 함수입니다. 

먼저 coco_names.txt 파일에서 클래스 이름을 읽어옵니다. 이 파일은 COCO 데이터셋에서 사용되는 클래스 이름을 담고 있습니다.
cv.dnn.readNet() 함수를 사용하여 YOLOv3 모델을 읽어옵니다. 이 함수는 모델의 가중치 파일(yolov3.weights)과 구성 파일(yolov3.cfg)을 읽어와서 모델을 생성합니다.
model.getLayerNames() 함수를 사용하여 모델의 모든 레이어 이름을 가져옵니다.
model.getUnconnectedOutLayers() 함수를 사용하여 모델의 출력 레이어를 가져옵니다.
out_layers 리스트에 출력 레이어의 이름을 저장합니다.
model, out_layers, class_names를 반환합니다.


이 함수를 호출하여 YOLOv3 모델, 출력 레이어, 클래스 이름을 얻을 수 있습니다.




```python

def yolo_detect(img,yolo_model,out_layers):
    height,width=img.shape[0],img.shape[1]
    test_img=cv.dnn.blobFromImage(img,1.0/256,(448,448),(0,0,0),swapRB=True)
    
    yolo_model.setInput(test_img)
    output3=yolo_model.forward(out_layers)
    
    box,conf,id=[],[],[]		# 박스, 신뢰도, 부류 번호
    for output in output3:
        for vec85 in output:
            scores=vec85[5:]
            class_id=np.argmax(scores)
            confidence=scores[class_id]
            if confidence>0.5:	# 신뢰도가 50% 이상인 경우만 취함
                centerx,centery=int(vec85[0]*width),int(vec85[1]*height)
                w,h=int(vec85[2]*width),int(vec85[3]*height)
                x,y=int(centerx-w/2),int(centery-h/2)
                box.append([x,y,x+w,y+h])
                conf.append(float(confidence))
                id.append(class_id)
            
    ind=cv.dnn.NMSBoxes(box,conf,0.5,0.4)
    objects=[box[i]+[conf[i]]+[id[i]] for i in range(len(box)) if i in ind]
    return objects
```

YOLOv3 모델을 사용하여 이미지에서 객체를 탐지하는 함수입니다.



먼저 입력 이미지의 높이와 너비를 가져옵니다.

cv.dnn.blobFromImage() 함수를 사용하여 입력 이미지를 모델에 적합한 형태로 변환합니다. 이 함수는 이미지를 정규화하고 크기를 조정합니다.
yolo_model.setInput() 함수를 사용하여 모델의 입력으로 변환된 이미지를 설정합니다.
yolo_model.forward() 함수를 사용하여 출력 레이어에서 예측된 객체 정보를 가져옵니다.
출력 레이어에서 각 객체의 위치, 신뢰도, 클래스 번호를 추출합니다. 신뢰도가 0.5 이상인 객체만 선택합니다.
cv.dnn.NMSBoxes() 함수를 사용하여 겹치는 객체를 제거합니다.
최종 객체 리스트를 반환합니다. 이 리스트는 객체의 위치(x1, y1, x2, y2), 신뢰도, 클래스 번호를 포함합니다.


이 함수를 호출하여 입력 이미지에서 객체를 탐지할 수 있습니다.






```python

model,out_layers,class_names=construct_yolo_v3()		# YOLO 모델 생성
colors=np.random.uniform(0,255,size=(len(class_names),3))	# 부류마다 색깔

img=cv.imread('soccer.jpg')
if img is None: sys.exit('파일이 없습니다.')

res=yolo_detect(img,model,out_layers)	# YOLO 모델로 물체 검출

for i in range(len(res)):			# 검출된 물체를 영상에 표시
    x1,y1,x2,y2,confidence,id=res[i]
    text=str(class_names[id])+'%.3f'%confidence
    cv.rectangle(img,(x1,y1),(x2,y2),colors[id],2)
    cv.putText(img,text,(x1,y1+30),cv.FONT_HERSHEY_PLAIN,1.5,colors[id],2)
```


 YOLOv3 모델을 사용하여 이미지에서 객체를 탐지하고, 탐지된 객체를 원본 이미지에 표시하는 코드입니다.



construct_yolo_v3() 함수를 사용하여 YOLOv3 모델, 출력 레이어, 클래스 이름을 가져옵니다.
클래스마다 랜덤한 색상을 생성합니다.
cv.imread() 함수를 사용하여 이미지를 읽어옵니다.
yolo_detect() 함수를 사용하여 이미지에서 객체를 탐지합니다.
검출된 객체를 원본 이미지에 표시합니다. 객체의 위치에는 사각형을 그리고, 객체의 클래스와 신뢰도를 텍스트로 표시합니다.


이 코드를 실행하여 입력 이미지에서 객체를 탐지하고, 탐지된 객체를 표시할 수 있습니다.






```python

cv.imshow("Object detection by YOLO v.3",img)

cv.waitKey()
cv.destroyAllWindows()
```
