---
layout: single
title:  "Deep learning model 구현하기 (4) "
---


# model + compile + fit

출처 : Thebook.io (모두의 딥러닝)



세월이 흐르면서 쌓인 방대한 데이터를 빅데이터라고 합니다. 

이 ‘빅데이터’는 분명히 머신 러닝과 딥러닝으로 하여금 사람에 버금가는 판단과 지능을 가질 수 있게끔 했습니다. 

하지만 데이터양이 많다고 해서 무조건 좋은 결과를 얻을 수 있는 것은 아닙니다. 

데이터양도 중요하지만, 그 안에 ‘필요한’ 데이터가 얼마나 있는가도 중요하기 때문입니다. 

그리고 준비된 데이터가 우리가 사용하려는 머신 러닝과 딥러닝에 얼마나 효율적으로 사용되게끔 가공되었는지 역시 중요합니다.


머신 러닝 프로젝트의 성공과 실패는 얼마나 좋은 데이터를 가지고 시작하느냐에 영향을 많이 받습니다. 

여기서 좋은 데이터란 한쪽으로 치우치지 않고, 불필요한 정보가 대량으로 포함되어 있지 않으며, 왜곡되지 않은 데이터를 의미합니다. 

이러한 데이터를 만들기 위해 머신 러닝, 딥러닝 개발자들은 데이터를 직접 들여다보고 분석할 수 있어야 합니다. 

내가 이루고 싶은 목적에 맞추어 가능한 한 많은 정보를 모았다면 이를 머신 러닝과 딥러닝에서 사용할 수 있게 잘 정제된 데이터 형식으로 바꾸어야 합니다. 

이 작업은 모든 머신 러닝, 딥러닝 프로젝트의 첫 단추이자 가장 중요한 작업입니다.



1. 환경 준비

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np
```


딥러닝을 구동하거나 데이터를 다루는 데 필요한 라이브러리들을 불러옵니다.

 
 



2. 데이터 준비

```python
!git clone https://github.com/taehojo/data.git
Data_set = np.loadtxt("./data/ThoraricSurgery3.csv", delimiter=",")
X = Data_set[:,0:16]
y = Data_set[:,16]  
```

준비된 수술 환자 정보 데이터를 나의 구글 코랩 계정에 저장합니다. 

해당 파일을 불러와 환자 상태의 기록에 해당하는 부분을 X로, 수술 1년 후 사망/생존 여부를 y로 지정합니다.

 
 
 

3. 구조 결정

```python
model = Sequential()
model.add(Dense(30, input_dim=16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
```

딥러닝 모델의 구조를 결정합니다. 여기에 설정된 대로 딥러닝을 수행합니다.

 
 
 

4. 모델 실행

```python
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X, y, epochs=5, batch_size=16)
```

딥러닝 모델을 실행합니다. 앞서 설정된 구조대로 실행하고 결과를 출력합니다.
