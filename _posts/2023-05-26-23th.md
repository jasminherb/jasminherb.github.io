---
layout: single
title:  "PyTorch - 사용자 정의 데이터를 활용한 이미지 분류(23) "
---

# 12장 사용자 정의 데이터를 활용한 이미지 분류

* 한글 폰트를 올바르게 출력하기 위한 설치 방법은 다음과 같다.


```python
!sudo apt-get install -y fonts-nanum* | tail -n 1
!sudo fc-cache -fv
!rm -rf ~/.cache/matplotlib
```

    debconf: unable to initialize frontend: Dialog
    debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)
    debconf: falling back to frontend: Readline
    debconf: unable to initialize frontend: Readline
    debconf: (This frontend requires a controlling tty.)
    debconf: falling back to frontend: Teletype
    dpkg-preconfigure: unable to re-open stdin: 
    Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
    /usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs
    /usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs
    /usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs
    /usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs
    /usr/share/fonts/truetype/nanum: caching, new cache contents: 31 fonts, 0 dirs
    /usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs
    /root/.local/share/fonts: skipping, no such directory
    /root/.fonts: skipping, no such directory
    /var/cache/fontconfig: cleaning cache directory
    /root/.cache/fontconfig: not cleaning non-existent cache directory
    /root/.fontconfig: not cleaning non-existent cache directory
    fc-cache: succeeded
    


```python
# 필요 라이브러리 설치

!pip install torchviz | tail -n 1
!pip install torchinfo | tail -n 1
w = !apt install tree
print(w[-2])
```

    Successfully installed torchviz-0.0.2
    Successfully installed torchinfo-1.6.5
    Setting up tree (1.7.0-5) ...
    

* 모든 설치가 끝나면 한글 폰트를 바르게 출력하기 위해 **[런타임]** -> **[런타임 다시시작]**을 클릭한 다음, 아래 셀부터 코드를 실행해 주십시오.


```python
# 라이브러리 임포트

%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import display

# 폰트 관련 용도
import matplotlib.font_manager as fm

# 나눔 고딕 폰트의 경로 명시
path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
font_name = fm.FontProperties(fname=path, size=10).get_name()
```


```python
# 파이토치 관련 라이브러리

import torch
from torch import tensor
import torch.nn as nn
import torch.optim as optim
from torchinfo import summary
from torchviz import make_dot
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torchvision.datasets as datasets
```


```python
# warning 표시 끄기
import warnings
warnings.simplefilter('ignore')

# 기본 폰트 설정
plt.rcParams['font.family'] = font_name

# 기본 폰트 사이즈 변경
plt.rcParams['font.size'] = 14

# 기본 그래프 사이즈 변경
plt.rcParams['figure.figsize'] = (6,6)

# 기본 그리드 표시
# 필요에 따라 설정할 때는, plt.grid()
plt.rcParams['axes.grid'] = True

# 마이너스 기호 정상 출력
plt.rcParams['axes.unicode_minus'] = False

# 넘파이 부동소수점 자릿수 표시
np.set_printoptions(suppress=True, precision=4)
```


```python
# GPU 디바이스 할당

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
```

    cuda:0
    

### 공통 함수 불러오기


```python
# 공통 함수 다운로드
!git clone https://github.com/wikibook/pythonlibs.git

# 공통 함수 불러오기
from pythonlibs.torch_lib1 import *

# 공통 함수 확인
print(README)
```

    Cloning into 'pythonlibs'...
    remote: Enumerating objects: 18, done.[K
    remote: Counting objects: 100% (18/18), done.[K
    remote: Compressing objects: 100% (13/13), done.[K
    remote: Total 18 (delta 2), reused 18 (delta 2), pack-reused 0[K
    Unpacking objects: 100% (18/18), done.
    Common Library for PyTorch
    Author: M. Akaishi
    

## 12.3 데이터 준비

### 데이터 다운로드, 압축 해제, 트리 구조 출력


```python
# 데이터 다운로드
w = !wget -nc https://download.pytorch.org/tutorial/hymenoptera_data.zip

# 결과 확인
print(w[-2])
```

    2022-04-10 14:24:10 (46.5 MB/s) - ‘hymenoptera_data.zip’ saved [47286322/47286322]
    


```python
# 압축 해제
w = !unzip -o hymenoptera_data.zip

# 결과 확인
print(w[-1])
```

      inflating: hymenoptera_data/val/bees/abeja.jpg  
    


```python
# 트리 구조 출력
!tree hymenoptera_data
```

    hymenoptera_data
    ├── train
    │   ├── ants
    │   │   ├── 0013035.jpg
    │   │   ├── 1030023514_aad5c608f9.jpg
    │   │   ├── 1095476100_3906d8afde.jpg
    │   │   ├── 1099452230_d1949d3250.jpg
    │   │   ├── 116570827_e9c126745d.jpg
    │   │   ├── 1225872729_6f0856588f.jpg
    │   │   ├── 1262877379_64fcada201.jpg
    │   │   ├── 1269756697_0bce92cdab.jpg
    │   │   ├── 1286984635_5119e80de1.jpg
    │   │   ├── 132478121_2a430adea2.jpg
    │   │   ├── 1360291657_dc248c5eea.jpg
    │   │   ├── 1368913450_e146e2fb6d.jpg
    │   │   ├── 1473187633_63ccaacea6.jpg
    │   │   ├── 148715752_302c84f5a4.jpg
    │   │   ├── 1489674356_09d48dde0a.jpg
    │   │   ├── 149244013_c529578289.jpg
    │   │   ├── 150801003_3390b73135.jpg
    │   │   ├── 150801171_cd86f17ed8.jpg
    │   │   ├── 154124431_65460430f2.jpg
    │   │   ├── 162603798_40b51f1654.jpg
    │   │   ├── 1660097129_384bf54490.jpg
    │   │   ├── 167890289_dd5ba923f3.jpg
    │   │   ├── 1693954099_46d4c20605.jpg
    │   │   ├── 175998972.jpg
    │   │   ├── 178538489_bec7649292.jpg
    │   │   ├── 1804095607_0341701e1c.jpg
    │   │   ├── 1808777855_2a895621d7.jpg
    │   │   ├── 188552436_605cc9b36b.jpg
    │   │   ├── 1917341202_d00a7f9af5.jpg
    │   │   ├── 1924473702_daa9aacdbe.jpg
    │   │   ├── 196057951_63bf063b92.jpg
    │   │   ├── 196757565_326437f5fe.jpg
    │   │   ├── 201558278_fe4caecc76.jpg
    │   │   ├── 201790779_527f4c0168.jpg
    │   │   ├── 2019439677_2db655d361.jpg
    │   │   ├── 207947948_3ab29d7207.jpg
    │   │   ├── 20935278_9190345f6b.jpg
    │   │   ├── 224655713_3956f7d39a.jpg
    │   │   ├── 2265824718_2c96f485da.jpg
    │   │   ├── 2265825502_fff99cfd2d.jpg
    │   │   ├── 226951206_d6bf946504.jpg
    │   │   ├── 2278278459_6b99605e50.jpg
    │   │   ├── 2288450226_a6e96e8fdf.jpg
    │   │   ├── 2288481644_83ff7e4572.jpg
    │   │   ├── 2292213964_ca51ce4bef.jpg
    │   │   ├── 24335309_c5ea483bb8.jpg
    │   │   ├── 245647475_9523dfd13e.jpg
    │   │   ├── 255434217_1b2b3fe0a4.jpg
    │   │   ├── 258217966_d9d90d18d3.jpg
    │   │   ├── 275429470_b2d7d9290b.jpg
    │   │   ├── 28847243_e79fe052cd.jpg
    │   │   ├── 318052216_84dff3f98a.jpg
    │   │   ├── 334167043_cbd1adaeb9.jpg
    │   │   ├── 339670531_94b75ae47a.jpg
    │   │   ├── 342438950_a3da61deab.jpg
    │   │   ├── 36439863_0bec9f554f.jpg
    │   │   ├── 374435068_7eee412ec4.jpg
    │   │   ├── 382971067_0bfd33afe0.jpg
    │   │   ├── 384191229_5779cf591b.jpg
    │   │   ├── 386190770_672743c9a7.jpg
    │   │   ├── 392382602_1b7bed32fa.jpg
    │   │   ├── 403746349_71384f5b58.jpg
    │   │   ├── 408393566_b5b694119b.jpg
    │   │   ├── 424119020_6d57481dab.jpg
    │   │   ├── 424873399_47658a91fb.jpg
    │   │   ├── 450057712_771b3bfc91.jpg
    │   │   ├── 45472593_bfd624f8dc.jpg
    │   │   ├── 459694881_ac657d3187.jpg
    │   │   ├── 460372577_f2f6a8c9fc.jpg
    │   │   ├── 460874319_0a45ab4d05.jpg
    │   │   ├── 466430434_4000737de9.jpg
    │   │   ├── 470127037_513711fd21.jpg
    │   │   ├── 474806473_ca6caab245.jpg
    │   │   ├── 475961153_b8c13fd405.jpg
    │   │   ├── 484293231_e53cfc0c89.jpg
    │   │   ├── 49375974_e28ba6f17e.jpg
    │   │   ├── 506249802_207cd979b4.jpg
    │   │   ├── 506249836_717b73f540.jpg
    │   │   ├── 512164029_c0a66b8498.jpg
    │   │   ├── 512863248_43c8ce579b.jpg
    │   │   ├── 518773929_734dbc5ff4.jpg
    │   │   ├── 522163566_fec115ca66.jpg
    │   │   ├── 522415432_2218f34bf8.jpg
    │   │   ├── 531979952_bde12b3bc0.jpg
    │   │   ├── 533848102_70a85ad6dd.jpg
    │   │   ├── 535522953_308353a07c.jpg
    │   │   ├── 540889389_48bb588b21.jpg
    │   │   ├── 541630764_dbd285d63c.jpg
    │   │   ├── 543417860_b14237f569.jpg
    │   │   ├── 560966032_988f4d7bc4.jpg
    │   │   ├── 5650366_e22b7e1065.jpg
    │   │   ├── 6240329_72c01e663e.jpg
    │   │   ├── 6240338_93729615ec.jpg
    │   │   ├── 649026570_e58656104b.jpg
    │   │   ├── 662541407_ff8db781e7.jpg
    │   │   ├── 67270775_e9fdf77e9d.jpg
    │   │   ├── 6743948_2b8c096dda.jpg
    │   │   ├── 684133190_35b62c0c1d.jpg
    │   │   ├── 69639610_95e0de17aa.jpg
    │   │   ├── 707895295_009cf23188.jpg
    │   │   ├── 7759525_1363d24e88.jpg
    │   │   ├── 795000156_a9900a4a71.jpg
    │   │   ├── 822537660_caf4ba5514.jpg
    │   │   ├── 82852639_52b7f7f5e3.jpg
    │   │   ├── 841049277_b28e58ad05.jpg
    │   │   ├── 886401651_f878e888cd.jpg
    │   │   ├── 892108839_f1aad4ca46.jpg
    │   │   ├── 938946700_ca1c669085.jpg
    │   │   ├── 957233405_25c1d1187b.jpg
    │   │   ├── 9715481_b3cb4114ff.jpg
    │   │   ├── 998118368_6ac1d91f81.jpg
    │   │   ├── Ant_1.jpg
    │   │   ├── ant photos.jpg
    │   │   ├── army-ants-red-picture.jpg
    │   │   ├── formica.jpeg
    │   │   ├── hormiga_co_por.jpg
    │   │   ├── imageNotFound.gif
    │   │   ├── kurokusa.jpg
    │   │   ├── MehdiabadiAnt2_600.jpg
    │   │   ├── Nepenthes_rafflesiana_ant.jpg
    │   │   ├── swiss-army-ant.jpg
    │   │   ├── termite-vs-ant.jpg
    │   │   ├── trap-jaw-ant-insect-bg.jpg
    │   │   └── VietnameseAntMimicSpider.jpg
    │   └── bees
    │       ├── 1092977343_cb42b38d62.jpg
    │       ├── 1093831624_fb5fbe2308.jpg
    │       ├── 1097045929_1753d1c765.jpg
    │       ├── 1232245714_f862fbe385.jpg
    │       ├── 129236073_0985e91c7d.jpg
    │       ├── 1295655112_7813f37d21.jpg
    │       ├── 132511197_0b86ad0fff.jpg
    │       ├── 132826773_dbbcb117b9.jpg
    │       ├── 150013791_969d9a968b.jpg
    │       ├── 1508176360_2972117c9d.jpg
    │       ├── 154600396_53e1252e52.jpg
    │       ├── 16838648_415acd9e3f.jpg
    │       ├── 1691282715_0addfdf5e8.jpg
    │       ├── 17209602_fe5a5a746f.jpg
    │       ├── 174142798_e5ad6d76e0.jpg
    │       ├── 1799726602_8580867f71.jpg
    │       ├── 1807583459_4fe92b3133.jpg
    │       ├── 196430254_46bd129ae7.jpg
    │       ├── 196658222_3fffd79c67.jpg
    │       ├── 198508668_97d818b6c4.jpg
    │       ├── 2031225713_50ed499635.jpg
    │       ├── 2037437624_2d7bce461f.jpg
    │       ├── 2053200300_8911ef438a.jpg
    │       ├── 205835650_e6f2614bee.jpg
    │       ├── 208702903_42fb4d9748.jpg
    │       ├── 21399619_3e61e5bb6f.jpg
    │       ├── 2227611847_ec72d40403.jpg
    │       ├── 2321139806_d73d899e66.jpg
    │       ├── 2330918208_8074770c20.jpg
    │       ├── 2345177635_caf07159b3.jpg
    │       ├── 2358061370_9daabbd9ac.jpg
    │       ├── 2364597044_3c3e3fc391.jpg
    │       ├── 2384149906_2cd8b0b699.jpg
    │       ├── 2397446847_04ef3cd3e1.jpg
    │       ├── 2405441001_b06c36fa72.jpg
    │       ├── 2445215254_51698ff797.jpg
    │       ├── 2452236943_255bfd9e58.jpg
    │       ├── 2467959963_a7831e9ff0.jpg
    │       ├── 2470492904_837e97800d.jpg
    │       ├── 2477324698_3d4b1b1cab.jpg
    │       ├── 2477349551_e75c97cf4d.jpg
    │       ├── 2486729079_62df0920be.jpg
    │       ├── 2486746709_c43cec0e42.jpg
    │       ├── 2493379287_4100e1dacc.jpg
    │       ├── 2495722465_879acf9d85.jpg
    │       ├── 2528444139_fa728b0f5b.jpg
    │       ├── 2538361678_9da84b77e3.jpg
    │       ├── 2551813042_8a070aeb2b.jpg
    │       ├── 2580598377_a4caecdb54.jpg
    │       ├── 2601176055_8464e6aa71.jpg
    │       ├── 2610833167_79bf0bcae5.jpg
    │       ├── 2610838525_fe8e3cae47.jpg
    │       ├── 2617161745_fa3ebe85b4.jpg
    │       ├── 2625499656_e3415e374d.jpg
    │       ├── 2634617358_f32fd16bea.jpg
    │       ├── 2638074627_6b3ae746a0.jpg
    │       ├── 2645107662_b73a8595cc.jpg
    │       ├── 2651621464_a2fa8722eb.jpg
    │       ├── 2652877533_a564830cbf.jpg
    │       ├── 266644509_d30bb16a1b.jpg
    │       ├── 2683605182_9d2a0c66cf.jpg
    │       ├── 2704348794_eb5d5178c2.jpg
    │       ├── 2707440199_cd170bd512.jpg
    │       ├── 2710368626_cb42882dc8.jpg
    │       ├── 2722592222_258d473e17.jpg
    │       ├── 2728759455_ce9bb8cd7a.jpg
    │       ├── 2756397428_1d82a08807.jpg
    │       ├── 2765347790_da6cf6cb40.jpg
    │       ├── 2781170484_5d61835d63.jpg
    │       ├── 279113587_b4843db199.jpg
    │       ├── 2792000093_e8ae0718cf.jpg
    │       ├── 2801728106_833798c909.jpg
    │       ├── 2822388965_f6dca2a275.jpg
    │       ├── 2861002136_52c7c6f708.jpg
    │       ├── 2908916142_a7ac8b57a8.jpg
    │       ├── 29494643_e3410f0d37.jpg
    │       ├── 2959730355_416a18c63c.jpg
    │       ├── 2962405283_22718d9617.jpg
    │       ├── 3006264892_30e9cced70.jpg
    │       ├── 3030189811_01d095b793.jpg
    │       ├── 3030772428_8578335616.jpg
    │       ├── 3044402684_3853071a87.jpg
    │       ├── 3074585407_9854eb3153.jpg
    │       ├── 3079610310_ac2d0ae7bc.jpg
    │       ├── 3090975720_71f12e6de4.jpg
    │       ├── 3100226504_c0d4f1e3f1.jpg
    │       ├── 342758693_c56b89b6b6.jpg
    │       ├── 354167719_22dca13752.jpg
    │       ├── 359928878_b3b418c728.jpg
    │       ├── 365759866_b15700c59b.jpg
    │       ├── 36900412_92b81831ad.jpg
    │       ├── 39672681_1302d204d1.jpg
    │       ├── 39747887_42df2855ee.jpg
    │       ├── 421515404_e87569fd8b.jpg
    │       ├── 444532809_9e931e2279.jpg
    │       ├── 446296270_d9e8b93ecf.jpg
    │       ├── 452462677_7be43af8ff.jpg
    │       ├── 452462695_40a4e5b559.jpg
    │       ├── 457457145_5f86eb7e9c.jpg
    │       ├── 465133211_80e0c27f60.jpg
    │       ├── 469333327_358ba8fe8a.jpg
    │       ├── 472288710_2abee16fa0.jpg
    │       ├── 473618094_8ffdcab215.jpg
    │       ├── 476347960_52edd72b06.jpg
    │       ├── 478701318_bbd5e557b8.jpg
    │       ├── 507288830_f46e8d4cb2.jpg
    │       ├── 509247772_2db2d01374.jpg
    │       ├── 513545352_fd3e7c7c5d.jpg
    │       ├── 522104315_5d3cb2758e.jpg
    │       ├── 537309131_532bfa59ea.jpg
    │       ├── 586041248_3032e277a9.jpg
    │       ├── 760526046_547e8b381f.jpg
    │       ├── 760568592_45a52c847f.jpg
    │       ├── 774440991_63a4aa0cbe.jpg
    │       ├── 85112639_6e860b0469.jpg
    │       ├── 873076652_eb098dab2d.jpg
    │       ├── 90179376_abc234e5f4.jpg
    │       ├── 92663402_37f379e57a.jpg
    │       ├── 95238259_98470c5b10.jpg
    │       ├── 969455125_58c797ef17.jpg
    │       └── 98391118_bdb1e80cce.jpg
    └── val
        ├── ants
        │   ├── 10308379_1b6c72e180.jpg
        │   ├── 1053149811_f62a3410d3.jpg
        │   ├── 1073564163_225a64f170.jpg
        │   ├── 1119630822_cd325ea21a.jpg
        │   ├── 1124525276_816a07c17f.jpg
        │   ├── 11381045_b352a47d8c.jpg
        │   ├── 119785936_dd428e40c3.jpg
        │   ├── 1247887232_edcb61246c.jpg
        │   ├── 1262751255_c56c042b7b.jpg
        │   ├── 1337725712_2eb53cd742.jpg
        │   ├── 1358854066_5ad8015f7f.jpg
        │   ├── 1440002809_b268d9a66a.jpg
        │   ├── 147542264_79506478c2.jpg
        │   ├── 152286280_411648ec27.jpg
        │   ├── 153320619_2aeb5fa0ee.jpg
        │   ├── 153783656_85f9c3ac70.jpg
        │   ├── 157401988_d0564a9d02.jpg
        │   ├── 159515240_d5981e20d1.jpg
        │   ├── 161076144_124db762d6.jpg
        │   ├── 161292361_c16e0bf57a.jpg
        │   ├── 170652283_ecdaff5d1a.jpg
        │   ├── 17081114_79b9a27724.jpg
        │   ├── 172772109_d0a8e15fb0.jpg
        │   ├── 1743840368_b5ccda82b7.jpg
        │   ├── 181942028_961261ef48.jpg
        │   ├── 183260961_64ab754c97.jpg
        │   ├── 2039585088_c6f47c592e.jpg
        │   ├── 205398178_c395c5e460.jpg
        │   ├── 208072188_f293096296.jpg
        │   ├── 209615353_eeb38ba204.jpg
        │   ├── 2104709400_8831b4fc6f.jpg
        │   ├── 212100470_b485e7b7b9.jpg
        │   ├── 2127908701_d49dc83c97.jpg
        │   ├── 2191997003_379df31291.jpg
        │   ├── 2211974567_ee4606b493.jpg
        │   ├── 2219621907_47bc7cc6b0.jpg
        │   ├── 2238242353_52c82441df.jpg
        │   ├── 2255445811_dabcdf7258.jpg
        │   ├── 239161491_86ac23b0a3.jpg
        │   ├── 263615709_cfb28f6b8e.jpg
        │   ├── 308196310_1db5ffa01b.jpg
        │   ├── 319494379_648fb5a1c6.jpg
        │   ├── 35558229_1fa4608a7a.jpg
        │   ├── 412436937_4c2378efc2.jpg
        │   ├── 436944325_d4925a38c7.jpg
        │   ├── 445356866_6cb3289067.jpg
        │   ├── 459442412_412fecf3fe.jpg
        │   ├── 470127071_8b8ee2bd74.jpg
        │   ├── 477437164_bc3e6e594a.jpg
        │   ├── 488272201_c5aa281348.jpg
        │   ├── 502717153_3e4865621a.jpg
        │   ├── 518746016_bcc28f8b5b.jpg
        │   ├── 540543309_ddbb193ee5.jpg
        │   ├── 562589509_7e55469b97.jpg
        │   ├── 57264437_a19006872f.jpg
        │   ├── 573151833_ebbc274b77.jpg
        │   ├── 649407494_9b6bc4949f.jpg
        │   ├── 751649788_78dd7d16ce.jpg
        │   ├── 768870506_8f115d3d37.jpg
        │   ├── 800px-Meat_eater_ant_qeen_excavating_hole.jpg
        │   ├── 8124241_36b290d372.jpg
        │   ├── 8398478_50ef10c47a.jpg
        │   ├── 854534770_31f6156383.jpg
        │   ├── 892676922_4ab37dce07.jpg
        │   ├── 94999827_36895faade.jpg
        │   ├── Ant-1818.jpg
        │   ├── ants-devouring-remains-of-large-dead-insect-on-red-tile-in-Stellenbosch-South-Africa-closeup-1-DHD.jpg
        │   ├── desert_ant.jpg
        │   ├── F.pergan.28(f).jpg
        │   └── Hormiga.jpg
        └── bees
            ├── 1032546534_06907fe3b3.jpg
            ├── 10870992_eebeeb3a12.jpg
            ├── 1181173278_23c36fac71.jpg
            ├── 1297972485_33266a18d9.jpg
            ├── 1328423762_f7a88a8451.jpg
            ├── 1355974687_1341c1face.jpg
            ├── 144098310_a4176fd54d.jpg
            ├── 1486120850_490388f84b.jpg
            ├── 149973093_da3c446268.jpg
            ├── 151594775_ee7dc17b60.jpg
            ├── 151603988_2c6f7d14c7.jpg
            ├── 1519368889_4270261ee3.jpg
            ├── 152789693_220b003452.jpg
            ├── 177677657_a38c97e572.jpg
            ├── 1799729694_0c40101071.jpg
            ├── 181171681_c5a1a82ded.jpg
            ├── 187130242_4593a4c610.jpg
            ├── 203868383_0fcbb48278.jpg
            ├── 2060668999_e11edb10d0.jpg
            ├── 2086294791_6f3789d8a6.jpg
            ├── 2103637821_8d26ee6b90.jpg
            ├── 2104135106_a65eede1de.jpg
            ├── 215512424_687e1e0821.jpg
            ├── 2173503984_9c6aaaa7e2.jpg
            ├── 220376539_20567395d8.jpg
            ├── 224841383_d050f5f510.jpg
            ├── 2321144482_f3785ba7b2.jpg
            ├── 238161922_55fa9a76ae.jpg
            ├── 2407809945_fb525ef54d.jpg
            ├── 2415414155_1916f03b42.jpg
            ├── 2438480600_40a1249879.jpg
            ├── 2444778727_4b781ac424.jpg
            ├── 2457841282_7867f16639.jpg
            ├── 2470492902_3572c90f75.jpg
            ├── 2478216347_535c8fe6d7.jpg
            ├── 2501530886_e20952b97d.jpg
            ├── 2506114833_90a41c5267.jpg
            ├── 2509402554_31821cb0b6.jpg
            ├── 2525379273_dcb26a516d.jpg
            ├── 26589803_5ba7000313.jpg
            ├── 2668391343_45e272cd07.jpg
            ├── 2670536155_c170f49cd0.jpg
            ├── 2685605303_9eed79d59d.jpg
            ├── 2702408468_d9ed795f4f.jpg
            ├── 2709775832_85b4b50a57.jpg
            ├── 2717418782_bd83307d9f.jpg
            ├── 272986700_d4d4bf8c4b.jpg
            ├── 2741763055_9a7bb00802.jpg
            ├── 2745389517_250a397f31.jpg
            ├── 2751836205_6f7b5eff30.jpg
            ├── 2782079948_8d4e94a826.jpg
            ├── 2809496124_5f25b5946a.jpg
            ├── 2815838190_0a9889d995.jpg
            ├── 2841437312_789699c740.jpg
            ├── 2883093452_7e3a1eb53f.jpg
            ├── 290082189_f66cb80bfc.jpg
            ├── 296565463_d07a7bed96.jpg
            ├── 3077452620_548c79fda0.jpg
            ├── 348291597_ee836fbb1a.jpg
            ├── 350436573_41f4ecb6c8.jpg
            ├── 353266603_d3eac7e9a0.jpg
            ├── 372228424_16da1f8884.jpg
            ├── 400262091_701c00031c.jpg
            ├── 416144384_961c326481.jpg
            ├── 44105569_16720a960c.jpg
            ├── 456097971_860949c4fc.jpg
            ├── 464594019_1b24a28bb1.jpg
            ├── 485743562_d8cc6b8f73.jpg
            ├── 540976476_844950623f.jpg
            ├── 54736755_c057723f64.jpg
            ├── 57459255_752774f1b2.jpg
            ├── 576452297_897023f002.jpg
            ├── 586474709_ae436da045.jpg
            ├── 590318879_68cf112861.jpg
            ├── 59798110_2b6a3c8031.jpg
            ├── 603709866_a97c7cfc72.jpg
            ├── 603711658_4c8cd2201e.jpg
            ├── 65038344_52a45d090d.jpg
            ├── 6a00d8341c630a53ef00e553d0beb18834-800wi.jpg
            ├── 72100438_73de9f17af.jpg
            ├── 759745145_e8bc776ec8.jpg
            ├── 936182217_c4caa5222d.jpg
            └── abeja.jpg
    
    6 directories, 398 files
    

### Transforms 정의


```python
# Transforms 정의

# 검증 데이터 : 정규화
test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5)
])

# 훈련 데이터 : 정규화에 반전과 RandomErasing 추가
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5),
    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)
])
```

### 데이터셋 정의


```python
# 베이스 디렉터리
data_dir = 'hymenoptera_data'

# 훈련 데이터 디렉터리와 검증 데이터 디렉터리 지정
import os
train_dir = os.path.join(data_dir, 'train')
test_dir = os.path.join(data_dir, 'val')

# join 함수 결과 확인
print(train_dir, test_dir)

# 분류하려는 클래스의 리스트 작성
classes = ['ants', 'bees']
```

    hymenoptera_data/train hymenoptera_data/val
    


```python
# 데이터셋 정의

# 훈련용
train_data = datasets.ImageFolder(train_dir, 
            transform=train_transform)
# 훈련 데이터 이미지 출력용
train_data2 = datasets.ImageFolder(train_dir, 
            transform=test_transform)
# 검증용
test_data = datasets.ImageFolder(test_dir, 
            transform=test_transform)
```


```python
# 데이터 건수 확인

print(f'훈련 데이터 : {len(train_data)} 건')
print(f'검증 데이터 : {len(test_data)} 건')
```

    훈련 데이터 : 244 건
    검증 데이터 : 153 건
    


```python
# 검증 데이터　
# 처음 10개와 마지막 10개 이미지 출력

plt.figure(figsize=(15, 4))
for i in range(10):
    ax = plt.subplot(2, 10, i + 1)
    image, label = test_data[i]
    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2
    plt.imshow(img)
    ax.set_title(classes[label])
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    ax = plt.subplot(2, 10, i + 11)
    image, label = test_data[-i-1]
    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2
    plt.imshow(img)
    ax.set_title(classes[label])
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()
```


    
![png](output_22_0.png)
    


### 데이터로더 정의


```python
# 데이터로더 정의

batch_size = 10

# 훈련용
train_loader = DataLoader(train_data, 
      batch_size=batch_size, shuffle=True)

# 검증용
test_loader = DataLoader(test_data, 
      batch_size=batch_size, shuffle=False)

# 이미지 출력용
train_loader2 = DataLoader(train_data2, 
      batch_size=50, shuffle=True)
test_loader2 = DataLoader(test_data, 
      batch_size=50, shuffle=True)
```

### 이미지 출력


```python
# 검증 데이터(50건)
torch_seed()
show_images_labels(test_loader2, classes, None, None)
```


    
![png](output_26_0.png)
    


## 12.4 파인 튜닝의 경우


```python
# 파인 튜닝의 경우

# 사전 학습 모델 불러오기
# VGG-19-BN 모델을 학습이 끝난 파라미터와 함께 불러오기
from torchvision import models
net = models.vgg19_bn(pretrained = True)

# 난수 고정
torch_seed()

# 최종 노드의 출력을 2로 변경
in_features = net.classifier[6].in_features
net.classifier[6] = nn.Linear(in_features, 2)

# AdaptiveAvgPool2d 함수 제거
net.avgpool = nn.Identity()

# GPU 사용
net = net.to(device)

# 학습률
lr = 0.001

# 손실 함수 정의
criterion = nn.CrossEntropyLoss()

# 최적화 함수 정의
optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)

# history 파일도 동시에 초기화
history = np.zeros((0, 5))
```


```python
# 학습
num_epochs = 5
history = fit(net, optimizer, criterion, num_epochs, 
          train_loader, test_loader, device, history)
```


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [1/5], loss: 0.04421 acc: 0.78689 val_loss: 0.01105, val_acc: 0.96078
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [2/5], loss: 0.01980 acc: 0.92213 val_loss: 0.01319, val_acc: 0.96732
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [3/5], loss: 0.02082 acc: 0.91803 val_loss: 0.01025, val_acc: 0.97386
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [4/5], loss: 0.01423 acc: 0.93443 val_loss: 0.01558, val_acc: 0.96078
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [5/5], loss: 0.01413 acc: 0.93443 val_loss: 0.01236, val_acc: 0.95425
    


```python
# 결과 확인
evaluate_history(history)
```

    초기상태 : 손실 : 0.01105  정확도 : 0.96078
    최종상태 : 손실 : 0.01236 정확도 : 0.95425
    


    
![png](output_30_1.png)
    



    
![png](output_30_2.png)
    



```python
# 난수 고정
torch_seed()

# 검증 데이터 결과 출력
show_images_labels(test_loader2, classes, net, device)
```


    
![png](output_31_0.png)
    



## 12.5 전이 학습의 경우


```python
# VGG-19-BN 모델을 학습이 끝난 파라미터와 함께 불러오기
from torchvision import models
net = models.vgg19_bn(pretrained = True)

# 모든 파라미터의 경사 계산을 OFF로 설정
for param in net.parameters():
    param.requires_grad = False

# 난수 고정
torch_seed()

# 최종 노드의 출력을 2로 변경
# 이 노드에 대해서만 경사 계산을 수행하게 됨
in_features = net.classifier[6].in_features
net.classifier[6] = nn.Linear(in_features, 2)

# AdaptiveAvgPool2d 함수 제거
net.avgpool = nn.Identity()

# GPU 사용
net = net.to(device)

# 학습률
lr = 0.001

# 손실 함수로 교차 엔트로피 사용
criterion = nn.CrossEntropyLoss()

# 최적화 함수 정의
# 파라미터 수정 대상을 최종 노드로 제한
optimizer = optim.SGD(net.classifier[6].parameters(),lr=lr,momentum=0.9)

# history 파일도 동시에 초기화
history = np.zeros((0, 5))
```


```python
# 학습
num_epochs = 5
history = fit(net, optimizer, criterion, num_epochs, 
          train_loader, test_loader, device, history)
```


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [1/5], loss: 0.04625 acc: 0.78279 val_loss: 0.01375, val_acc: 0.96078
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [2/5], loss: 0.02263 acc: 0.92213 val_loss: 0.01272, val_acc: 0.96078
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [3/5], loss: 0.02457 acc: 0.90164 val_loss: 0.01185, val_acc: 0.95425
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [4/5], loss: 0.02028 acc: 0.90164 val_loss: 0.01275, val_acc: 0.95425
    


      0%|          | 0/25 [00:00<?, ?it/s]


    Epoch [5/5], loss: 0.02133 acc: 0.88934 val_loss: 0.01191, val_acc: 0.96078
    


```python
# 결과 확인
evaluate_history(history)
```

    초기상태 : 손실 : 0.01375  정확도 : 0.96078
    최종상태 : 손실 : 0.01191 정확도 : 0.96078
    


    
![png](output_35_1.png)
    



    
![png](output_35_2.png)
    



```python
# 난수 고정
torch_seed()

# 검증 데이터 결과 출력
show_images_labels(test_loader2, classes, net, device)
```


    
![png](output_36_0.png)
    


## 12.6 사용자 정의 데이터를 사용하는 경우
시베리안 허스키와 늑대 이미지를 사용함

### 데이터 다운로드, 압축 해제


```python
# 데이터 다운로드
w = !wget https://github.com/makaishi2/pythonlibs/raw/main/images/dog_wolf.zip
print(w[-2])

# 압축 해제
!unzip dog_wolf.zip | tail -n 1

# 트리 구조 확인
!tree dog_wolf
```

    2022-04-10 14:43:13 (142 MB/s) - ‘dog_wolf.zip’ saved [21811374/21811374]
      inflating: dog_wolf/train/wolf/wolf-09.png  
    dog_wolf
    ├── test
    │   ├── dog
    │   │   ├── dog-21.png
    │   │   ├── dog-22.png
    │   │   ├── dog-23.png
    │   │   ├── dog-24.png
    │   │   └── dog-25.png
    │   └── wolf
    │       ├── wolf-21.png
    │       ├── wolf-22.png
    │       ├── wolf-23.png
    │       ├── wolf-24.png
    │       └── wolf-25.png
    └── train
        ├── dog
        │   ├── dog-01.png
        │   ├── dog-02.png
        │   ├── dog-03.png
        │   ├── dog-04.png
        │   ├── dog-05.png
        │   ├── dog-06.png
        │   ├── dog-07.png
        │   ├── dog-08.png
        │   ├── dog-09.png
        │   ├── dog-10.png
        │   ├── dog-11.png
        │   ├── dog-12.png
        │   ├── dog-13.png
        │   ├── dog-14.png
        │   ├── dog-15.png
        │   ├── dog-16.png
        │   ├── dog-17.png
        │   ├── dog-18.png
        │   ├── dog-19.png
        │   └── dog-20.png
        └── wolf
            ├── wolf-01.png
            ├── wolf-02.png
            ├── wolf-03.png
            ├── wolf-04.png
            ├── wolf-05.png
            ├── wolf-06.png
            ├── wolf-07.png
            ├── wolf-08.png
            ├── wolf-09.png
            ├── wolf-10.png
            ├── wolf-11.png
            ├── wolf-12.png
            ├── wolf-13.png
            ├── wolf-14.png
            ├── wolf-15.png
            ├── wolf-16.png
            ├── wolf-17.png
            ├── wolf-18.png
            ├── wolf-19.png
            └── wolf-20.png
    
    6 directories, 50 files
    

### Transforms 정의


```python
# Transforms 정의

# 검증 데이터 : 정규화
test_transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5)
])

# 훈련 데이터 : 정규화에 반전과 RandomErasing 추가
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5), 
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(0.5, 0.5),
    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)   
])
```

### 데이터셋 정의


```python
# 데이터셋 정의

data_dir = 'dog_wolf'

import os
train_dir = os.path.join(data_dir, 'train')
test_dir = os.path.join(data_dir, 'test')

classes = ['dog', 'wolf']

train_data = datasets.ImageFolder(train_dir, 
            transform=train_transform)
train_data2 = datasets.ImageFolder(train_dir, 
            transform=test_transform)
test_data = datasets.ImageFolder(test_dir, 
            transform=test_transform)
```


```python
# 데이터 건수 확인

print(f'학습 데이터 : {len(train_data)} 건')
print(f'검증 데이터 : {len(test_data)} 건')
```

    학습 데이터 : 40 건
    검증 데이터 : 10 건
    

### 데이터로더 정의


```python
# 데이터로더 정의

batch_size = 5
# 훈련 데이터
train_loader = DataLoader(train_data, 
            batch_size=batch_size, shuffle=True)
# 훈련 데이터, 이미지 출력용
train_loader2 = DataLoader(train_data2, 
            batch_size=40, shuffle=False)
# 검증 데이터
test_loader = DataLoader(test_data, 
            batch_size=batch_size, shuffle=False)
# 검증데이터, 이미지 출력용
test_loader2 = DataLoader(test_data, 
            batch_size=10, shuffle=True)
```

### 이미지 출력


```python
# 훈련 데이터(40건)
show_images_labels(train_loader2, classes, None, None)
```


    
![png](output_48_0.png)
    



```python
# 검증 데이터(10건)
torch_seed()
show_images_labels(test_loader2, classes, None, None)
```


    
![png](output_49_0.png)
    


### 모델 정의


```python
# 사전 학습 모델 불러오기
net = models.vgg19_bn(pretrained = True)

for param in net.parameters():
    param.requires_grad = False

# 난수 고정
torch_seed()

# 마지막 노드 출력을 2로 변경
in_features = net.classifier[6].in_features
net.classifier[6] = nn.Linear(in_features, 2)

# AdaptiveAvgPool2d 함수 제거
net.avgpool = nn.Identity()

# GPU 사용
net = net.to(device)

# 학습률
lr = 0.001

# 손실 함수 정의
criterion = nn.CrossEntropyLoss()

# 최적화 함수 정의
# 파라미터 수정 대상을 최종 노드로 제한
optimizer = optim.SGD(net.classifier[6].parameters(),lr=lr,momentum=0.9)

# history 파일도 동시에 초기화
history = np.zeros((0, 5))
```


```python
# 학습
num_epochs = 10
history = fit(net, optimizer, criterion, num_epochs, 
          train_loader, test_loader, device, history)
```


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [1/10], loss: 0.12345 acc: 0.65000 val_loss: 0.07783, val_acc: 1.00000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [2/10], loss: 0.07584 acc: 0.85000 val_loss: 0.04895, val_acc: 0.90000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [3/10], loss: 0.03976 acc: 0.92500 val_loss: 0.05762, val_acc: 0.80000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [4/10], loss: 0.04213 acc: 0.92500 val_loss: 0.03992, val_acc: 1.00000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [5/10], loss: 0.01836 acc: 0.97500 val_loss: 0.02970, val_acc: 1.00000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [6/10], loss: 0.02144 acc: 0.97500 val_loss: 0.04182, val_acc: 0.90000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [7/10], loss: 0.03019 acc: 0.95000 val_loss: 0.03631, val_acc: 0.90000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [8/10], loss: 0.04319 acc: 0.92500 val_loss: 0.03186, val_acc: 1.00000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [9/10], loss: 0.01086 acc: 1.00000 val_loss: 0.02766, val_acc: 1.00000
    


      0%|          | 0/8 [00:00<?, ?it/s]


    Epoch [10/10], loss: 0.04419 acc: 0.92500 val_loss: 0.03189, val_acc: 1.00000
    


```python
# 결과 확인
evaluate_history(history)
```

    초기상태 : 손실 : 0.07783  정확도 : 1.00000
    최종상태 : 손실 : 0.03189 정확도 : 1.00000
    


    
![png](output_53_1.png)
    



    
![png](output_53_2.png)
    



```python
# 예측 결과 출력
torch_seed()
show_images_labels(test_loader2, classes, net, device)
```


    
![png](output_54_0.png)
    

